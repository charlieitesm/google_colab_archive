{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_LSTM_imdb_clase.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aJKuX0wIHjx",
        "colab_type": "text"
      },
      "source": [
        "# Ejemplo de RNN-Simple y LSTM - Large Movie Review Dataset - Imdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAEpDEU9IWgh",
        "colab_type": "text"
      },
      "source": [
        "http://ai.stanford.edu/~amaas/data/sentiment/ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJWesW2YHUYd",
        "colab_type": "code",
        "outputId": "96c6c989-948f-407c-82f6-9fbbf6f5473d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3kah5wYNFvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvPaEQZ-MkO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_imdb = \"/content/drive/My Drive/data/aclImdb/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQDerfdQM5Sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(path_imdb, 'train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pDEOeItNTQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = []\n",
        "texts = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8BdyUZsNmNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for label_type in ['neg', 'pos']:\n",
        "  dir_label_type = os.path.join(train_dir, label_type)\n",
        "  for name in os.listdir(dir_label_type):\n",
        "    if fname[-4:] == '.txt':\n",
        "      f = open(os.path.join(dir_label_type, fname))\n",
        "      texts.append(f.read())\n",
        "      f.close()\n",
        "      if label_type == 'neg':\n",
        "        labels.append(0)\n",
        "      else:\n",
        "        labels.append(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFcMn-qknJ2e",
        "colab_type": "text"
      },
      "source": [
        "#Tokenizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvwBuBYlnIf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9r5kZ5In1jS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 100  # usamos solo las primeras 100 palabras de cada documento-reseña.\n",
        "training_samples = 200  # Por simplicidad entrenamos solo con pocos casos.\n",
        "validation_samples = 10000  # validation set\n",
        "max_words = 10000  # tamaño del vocabulario a considerar."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhsFf_VtogWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHf058CZoOYn",
        "colab_type": "code",
        "outputId": "d466d56c-b720-40c2-a6a2-3a0c7701c05b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "print(len(word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 0 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL982iUGGBqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pad_sequences(sequences, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi7Sn78lFm8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.asarray(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG0osxmRFsbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt7jw18AF0T3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NW7TyVVGDzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_test = data[training_samples: training_samples + validation_samples]\n",
        "y_test = labels[training_samples: training_samples + validation_samples]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WexOpDWaGv-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 1000 # 10000 # total de palabras deiferentes a considerar.\n",
        "n_epochs = 10\n",
        "n_batch = 128\n",
        "embedded_vector_sz = 32 # tamaño de los word embeddings."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnNPEmfFG6_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedded_vector_sz = 32))\n",
        "model.add(SimpleRNN(32))\n",
        "#model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJBB2y7hHdmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkEUJSizMIf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMlQKzwaHg83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "H = model.fit(x_train, y_train,\n",
        "                    epochs=n_epochs,\n",
        "                    batch_size=n_batch,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9CU3CBCLs37",
        "colab_type": "text"
      },
      "source": [
        "Recuerda, en el caso de usar validation split, estás considerando que el conjunto total de datos está dividido en Training, Validation y Testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkJMX-6YICJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0,n_epochs),H.history[\"accuracy\"],label=\"train_acc\")\n",
        "plt.plot(np.arange(0,n_epochs),H.history[\"val_accuracy\"],label=\"val_acc\")\n",
        "plt.title(\"Training and Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0,n_epochs),H.history[\"loss\"],label=\"train_loss\") \n",
        "plt.plot(np.arange(0,n_epochs),H.history[\"val_loss\"],label=\"val_loss\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDhoNZ6ZMe9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGT50bzyM1Zo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBSTfiJvM29y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Loss: %f' % (loss))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}